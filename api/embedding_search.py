"""
ì„ë² ë”© ê¸°ë°˜ ì˜ë¯¸ ê²€ìƒ‰ ëª¨ë“ˆ
Ollamaë¥¼ í™œìš©í•˜ì—¬ ì§ˆë¬¸ì˜ ì˜ë¯¸ë¥¼ ì´í•´í•˜ê³  ìœ ì‚¬í•œ ê°œë…ì„ ì°¾ìŠµë‹ˆë‹¤.
"""
import requests
import numpy as np
from typing import List, Dict, Tuple

class EmbeddingSearcher:
    def __init__(self, ollama_url: str, model: str = "mistral"):
        self.ollama_url = ollama_url
        self.model = model
    
    def get_embedding(self, text: str) -> List[float]:
        """í…ìŠ¤íŠ¸ì˜ ì„ë² ë”© ë²¡í„° ìƒì„±"""
        try:
            resp = requests.post(
                f"{self.ollama_url}/api/embeddings",
                json={"model": self.model, "prompt": text},
                timeout=30
            )
            resp.raise_for_status()
            return resp.json().get("embedding", [])
        except Exception as e:
            print(f"ì„ë² ë”© ìƒì„± ì‹¤íŒ¨: {e}")
            return []
    
    def cosine_similarity(self, vec1: List[float], vec2: List[float]) -> float:
        """ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°"""
        if not vec1 or not vec2:
            return 0.0
        
        a = np.array(vec1)
        b = np.array(vec2)
        
        norm_a = np.linalg.norm(a)
        norm_b = np.linalg.norm(b)
        
        if norm_a == 0 or norm_b == 0:
            return 0.0
        
        return float(np.dot(a, b) / (norm_a * norm_b))
    
    def extract_keywords(self, query: str) -> List[str]:
        """LLMì„ ì‚¬ìš©í•˜ì—¬ í•µì‹¬ í‚¤ì›Œë“œ ì¶”ì¶œ"""
        prompt = f"""ë‹¤ìŒ ì§ˆë¬¸ì—ì„œ í•µì‹¬ ê°œë… í‚¤ì›Œë“œë¥¼ ì¶”ì¶œí•˜ì„¸ìš”. 
ì§ˆë¬¸: {query}

í•µì‹¬ í‚¤ì›Œë“œë§Œ ì‰¼í‘œë¡œ êµ¬ë¶„í•˜ì—¬ ë‚˜ì—´í•˜ì„¸ìš”. ì¡°ì‚¬ë‚˜ ë¶ˆí•„ìš”í•œ ë‹¨ì–´ëŠ” ì œì™¸í•©ë‹ˆë‹¤.
ì˜ˆ: ì‚¬ë‘ì´ë€ ë¬´ì—‡ì¸ê°€? -> ì‚¬ë‘, ê°ì •, ì˜ë¯¸

í‚¤ì›Œë“œ:"""
        
        try:
            resp = requests.post(
                f"{self.ollama_url}/api/generate",
                json={"model": self.model, "prompt": prompt, "stream": False},
                timeout=30
            )
            resp.raise_for_status()
            keywords_text = resp.json().get("response", "").strip()
            
            # ì‰¼í‘œë¡œ ë¶„ë¦¬í•˜ê³  ì •ë¦¬
            keywords = [k.strip() for k in keywords_text.split(',')]
            keywords = [k for k in keywords if k and len(k) > 1]
            
            return keywords[:5]  # ìµœëŒ€ 5ê°œ
        except Exception as e:
            print(f"í‚¤ì›Œë“œ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            # í´ë°±: ë‹¨ìˆœ ê³µë°± ë¶„ë¦¬
            return [w for w in query.split() if len(w) > 1][:3]
    
    def search_with_embedding(
        self, 
        graph, 
        query: str, 
        k: int = 8
    ) -> Tuple[List[Dict], List[str]]:
        """
        ì„ë² ë”© ê¸°ë°˜ ê°œë… ê²€ìƒ‰
        
        Returns:
            (concepts, keywords): ì°¾ì€ ê°œë… ë¦¬ìŠ¤íŠ¸ì™€ ì‚¬ìš©ëœ í‚¤ì›Œë“œ
        """
        # 1. í‚¤ì›Œë“œ ì¶”ì¶œ
        keywords = self.extract_keywords(query)
        print(f"ğŸ” ì¶”ì¶œëœ í‚¤ì›Œë“œ: {keywords}")
        
        # 2. ê° í‚¤ì›Œë“œë¡œ ê°œë… ê²€ìƒ‰
        all_concepts = []
        seen_uris = set()
        
        for keyword in keywords:
            # í•œêµ­ì–´ ê°œë… ìš°ì„  ê²€ìƒ‰
            concepts = graph.run("""
                MATCH (c:Concept)
                WHERE c.language = 'ko' 
                  AND (toLower(c.label) CONTAINS toLower($kw)
                       OR toLower(c.label) = toLower($kw))
                RETURN c.uri as uri, c.label as label, c.language as lang
                LIMIT $k
                """, kw=keyword, k=k).data()
            
            for c in concepts:
                if c['uri'] not in seen_uris:
                    all_concepts.append(c)
                    seen_uris.add(c['uri'])
            
            # ì—°ê´€ ê°œë…ë„ íƒìƒ‰ (1-hop)
            if concepts:
                uris = [c['uri'] for c in concepts]
                related = graph.run("""
                    MATCH (c1:Concept)-[:RELATED]-(c2:Concept)
                    WHERE c1.uri IN $uris AND c2 <> c1
                    RETURN DISTINCT c2.uri as uri, c2.label as label, c2.language as lang
                    LIMIT $k
                    """, uris=uris, k=k).data()
                
                for c in related:
                    if c['uri'] not in seen_uris:
                        all_concepts.append(c)
                        seen_uris.add(c['uri'])
        
        # 3. ì„ë² ë”© ê¸°ë°˜ ì¬ìˆœìœ„í™” (ì˜µì…˜)
        # ì‹œê°„ì´ ì˜¤ë˜ ê±¸ë¦¬ë¯€ë¡œ ê°œë…ì´ ë§ì„ ë•Œë§Œ ì‚¬ìš©
        if len(all_concepts) > k * 2:
            query_emb = self.get_embedding(query)
            if query_emb:
                concept_scores = []
                for c in all_concepts:
                    label_emb = self.get_embedding(c['label'])
                    similarity = self.cosine_similarity(query_emb, label_emb)
                    concept_scores.append((c, similarity))
                
                # ìœ ì‚¬ë„ ìˆœìœ¼ë¡œ ì •ë ¬
                concept_scores.sort(key=lambda x: x[1], reverse=True)
                all_concepts = [c for c, _ in concept_scores[:k*2]]
        
        return all_concepts[:k*2], keywords
